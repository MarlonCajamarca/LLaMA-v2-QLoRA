{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "279857d6-cad9-4cc7-b359-e97d3a283650",
   "metadata": {},
   "source": [
    "# PEFT LLaMA-2 + Quantization + FastAttention\n",
    "_________________\n",
    "## Installing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112f2eb2-ec4e-49bf-a90f-2dea4381f628",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!apt update -y\n",
    "!pip install --upgrade pip\n",
    "!pip install \"transformers==4.31.0\" \"datasets==2.13.0\" \"peft==0.4.0\" \"accelerate==0.21.0\" \"bitsandbytes==0.40.2\" \"trl==0.4.7\" \"safetensors>=0.3.1\" \"huggingface_hub>=0.16.4\" \"python-dotenv==1.0.0\" \"openai>=0.27.8\" \"langchain[llm]\" \"git-lfs\" --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40be6b53-2f6a-4d0f-afd1-4fef547e73ee",
   "metadata": {},
   "source": [
    "## Installing Fast Attention Optimization\n",
    "If you are runnig from a newly created environment where the last version of fast-attn (V2) pytorch library is not compiled, you MUST uncomment the following lines and compile the library. This would take around 45-60 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53db40b-f44f-4ba3-b1fe-9563baa88b15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install ninja packaging\n",
    "# # start time 2:21 pm - end time 3 11\n",
    "# !MAX_JOBS=4 pip install flash-attn==2.0.4 --no-build-isolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9715a0f-8c70-471e-a806-0c7df8eaf361",
   "metadata": {},
   "source": [
    "If you want to check that the fast-attn v2 library is already compiled and working, uncomment the following lines of code and check that the `FlashAttnVarlenQKVPackedFunc` function exist with the `flash_attn_interface.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c38c794-1b10-4aa2-847e-c77540fb2155",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Command to check that the FlashAttnVarlenQKVPackedFunc is already compiled for posterior usage\n",
    "# !cat /opt/conda/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0715031d-b415-420e-9fcb-d8c74b7fb229",
   "metadata": {},
   "source": [
    "## Login into HuggingFace Hub\n",
    "-------------\n",
    "Provide your HuggingFace User Token in order to upload/download models, tokenizers and dataset from the hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12e98b7-f325-40d6-a414-caf1f899c8b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !huggingface-cli login --token {}\n",
    "!huggingface-cli login --token <YOUR HUGGING FACE TOKEN>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278106ab-71eb-4deb-ae3c-56370f2e727c",
   "metadata": {},
   "source": [
    "## Defining training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23b343f-2aaf-42d2-835e-2d3db244c0b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# Flash Attention parameters\n",
    "########################################\n",
    "use_flash_attention = True\n",
    "\n",
    "########################################\n",
    "# TrainingArguments parameters\n",
    "########################################\n",
    "model_name = 'meta-llama/Llama-2-7b-hf'\n",
    "dataset_name = \"mlabonne/guanaco-llama2-1k\"\n",
    "output_dir = \"./LLaMA2-QLoRA\"\n",
    "output_model_name = \"Llama-2-7b-hf_guanaco-llama2-1k_3-epochs_FastAtt-custom\"\n",
    "\n",
    "# Training iterations. Could be done by epochs OR by steps\n",
    "num_train_epochs = 3\n",
    "max_steps = -1\n",
    "\n",
    "# Batch size settings\n",
    "per_device_train_batch_size = 6 if use_flash_attention else 4\n",
    "per_device_eval_batch_size = 4\n",
    "group_by_length = True\n",
    "\n",
    "# Learning rate settings\n",
    "learning_rate = 2e-4\n",
    "lr_scheduler_type = \"constant\"\n",
    "\n",
    "# Weigths initialization and regularization\n",
    "weight_decay = 0.001\n",
    "warmup_ratio = 0.03\n",
    "\n",
    "# Optimizer and gradient settings\n",
    "optim = \"paged_adamw_32bit\"\n",
    "gradient_accumulation_steps = 2\n",
    "max_grad_norm = 0.3\n",
    "gradient_checkpointing = True\n",
    "\n",
    "# Mixed precision settings\n",
    "fp16 = False\n",
    "bf16 = True\n",
    "tf32 = True\n",
    "\n",
    "# Save and logging settings.\n",
    "# The checkpoint save strategy to adopt during training. Possible values are:\n",
    "# - \"no\": No save is done during training. \n",
    "# - \"epoch\": Save is done at the end of each epoch.\n",
    "# - \"steps\": Save is done every save_steps.\n",
    "save_strategy = \"epoch\"\n",
    "save_steps = 10\n",
    "logging_strategy = \"steps\"\n",
    "logging_steps = 10\n",
    "\n",
    "########################################\n",
    "# QLoRA parameters\n",
    "########################################\n",
    "lora_alpha = 16\n",
    "lora_dropout = 0.1\n",
    "lora_r = 64\n",
    "\n",
    "########################################\n",
    "# bitsandbytes parameters\n",
    "########################################\n",
    "use_4bit = True\n",
    "use_nested_quant = True \n",
    "bnb_4bit_compute_dtype = \"bfloat16\" \n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "########################################\n",
    "# SFT parameters\n",
    "########################################\n",
    "max_seq_length = 2048\n",
    "merge_weights = True\n",
    "push_weights = False\n",
    "packing = False\n",
    "\n",
    "# PEFT Command \n",
    "peft_command = f\"python llama2_peft_training.py \\\n",
    "--model_name {model_name} \\\n",
    "--dataset_name {dataset_name} \\\n",
    "--output_dir {output_dir} \\\n",
    "--output_model_name {output_model_name} \\\n",
    "--num_train_epochs {num_train_epochs} \\\n",
    "--max_steps {max_steps} \\\n",
    "--per_device_train_batch_size {per_device_train_batch_size} \\\n",
    "--per_device_eval_batch_size {per_device_eval_batch_size} \\\n",
    "--group_by_length {group_by_length} \\\n",
    "--learning_rate {learning_rate} \\\n",
    "--lr_scheduler_type {lr_scheduler_type} \\\n",
    "--weight_decay {weight_decay} \\\n",
    "--warmup_ratio {warmup_ratio} \\\n",
    "--optim {optim} \\\n",
    "--gradient_accumulation_steps {gradient_accumulation_steps} \\\n",
    "--max_grad_norm {max_grad_norm} \\\n",
    "--gradient_checkpointing {gradient_checkpointing} \\\n",
    "--fp16 {fp16} \\\n",
    "--bf16 {bf16} \\\n",
    "--tf32 {tf32} \\\n",
    "--lora_alpha {lora_alpha} \\\n",
    "--lora_dropout {lora_dropout} \\\n",
    "--lora_r {lora_r} \\\n",
    "--use_4bit {use_4bit} \\\n",
    "--use_nested_quant {use_nested_quant} \\\n",
    "--bnb_4bit_compute_dtype {bnb_4bit_compute_dtype} \\\n",
    "--bnb_4bit_quant_type {bnb_4bit_quant_type} \\\n",
    "--max_seq_length {max_seq_length} \\\n",
    "--merge_weights {merge_weights} \\\n",
    "--push_weights {push_weights} \\\n",
    "--use_flash_attention {use_flash_attention}\"\n",
    "\n",
    "# For inspecting if peft command is well-formed\n",
    "print(peft_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e424b580-0c7b-48c2-98eb-5cc9c5dd08bc",
   "metadata": {},
   "source": [
    "## Launching PEFT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29179aa3-dbcc-420f-ba17-f03d6d328f93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Executing peft command\n",
    "os.system(peft_command)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "kernelspec": {
   "display_name": "python3 (custom-pytorch-200-gpu-fastattention/1)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:806146483249:image-version/custom-pytorch-200-gpu-fastattention/1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
